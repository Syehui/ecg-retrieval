{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input\n",
      "/kaggle/input/ecgdata\n",
      "/kaggle/input/ecgdata/hf_round1_testA\n",
      "/kaggle/input/ecgdata/hf_round1_train\n",
      "/kaggle/input/prepare-round1-data\n",
      "/kaggle/working/__notebook__.ipynb\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load in \n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import math\n",
    "from IPython.display import FileLink\n",
    "\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    print(dirname)\n",
    "    #for filename in filenames: print(os.path.join(dirname, filename))\n",
    "\n",
    "for dirname, _, filenames in os.walk('/kaggle/working'):\n",
    "    for filename in filenames: \n",
    "        print(os.path.join(dirname, filename))\n",
    "# Any results you write to the current directory are saved as output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:15: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "072f25c7b8ba4c948b04cbb9cafe123f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24106.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "!cp ../input/prepare-round1-data/disease_dict_round1.pickle .\n",
    "\n",
    "from random import shuffle\n",
    "import gzip\n",
    "round1_add = '../input/prepare-round1-data/tianchi_round1.gz'\n",
    "round1_f = gzip.open(round1_add,'rt')\n",
    "datas = []\n",
    "for line in round1_f:\n",
    "    datas.append(line)\n",
    "\n",
    "shuffle(datas)\n",
    "\n",
    "f = gzip.open('tianchi_round1.gz','wt+')\n",
    "#f = open('tianchi_round1','w+')\n",
    "for line in tqdm(datas):\n",
    "    f.write(line)\n",
    "    if line[-1] != '\\n':\n",
    "        f.write('\\n')\n",
    "\n",
    "#sum([1 for line in open('tianchi_round1')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def load_labels(path):\\n    #load labels\\n    labels = []\\n    with open(path,\\'r\\') as f:\\n        for count, line in tqdm(enumerate(f)):\\n            datas = line.split()\\n            diseases = []\\n            exist_age = 0\\n            exist_sex = 0\\n            if datas[1].isdigit():  exist_age = 1\\n            if datas[1] == \\'MALE\\' or datas[1] == \\'FEMALE\\' : exist_sex = 1\\n            if len(datas) > 2 and (datas[2] == \\'MALE\\' or datas[2] == \\'FEMALE\\') : exist_sex = 1\\n            for disease in datas[1+exist_age+exist_sex:]:\\n                diseases.append(disease_dict[disease])\\n            labels.append(diseases)\\n\\n    #transfer labels to one-hot\\n    hot_labels = []\\n    for label in labels:\\n        hot = [0]*len(disease_dict)\\n        for disease in label:\\n            hot[disease] = 1\\n        hot_labels.append(hot)\\n    hot_labels = torch.FloatTensor(hot_labels)\\n    hot_labels.shape\\n\\n    num_dict = {}\\n    for dis in labels:\\n        for di in dis:\\n            num_dict[di] = num_dict.get(di,0) + 1\\n    #dict(sorted(num_dict.items()))\\n    return labels, hot_labels, num_dict\\nlabels, hot_labels, num_dict = load_labels(\\'/kaggle/input/ecgdata/hf_round1_label.txt\\')\\n#labels, hot_labels, num_dict = load_labels(\\'/kaggle/input/hf-round2-train/hf_round2_train.txt\\')\\n\\n#load diseases dict\\nimport pickle\\ndef load_disease_dict(path):\\n    disease_dict = {}\\n    with open(path,\\'r\\') as dict_f:\\n        for count, line in enumerate(dict_f):\\n            disease_dict[line.replace(\\'\\n\\',\\'\\')] = count\\n    return disease_dict\\ndisease_dict = load_disease_dict(\\'/kaggle/input/ecgdata/hf_round1_arrythmia.txt\\')\\npickle.dump(disease_dict,open(\\'disease_dict_round1.pickle\\',\\'wb+\\'))\\nprint(disease_dict)\\n‘’‘\\nprint({k: v for k, v in sorted(num_dict.items(), key=lambda item: item[1], reverse=True)})\\nfor key in disease_dict:\\n    index = disease_dict[key]\\n    disease_dict[key] = num_dict[index]\\nprint({k: v for k, v in sorted(disease_dict.items(), key=lambda item: item[1], reverse=True)})\\n’‘’\\n\\nto_123 = {}\\nto_123[\\'窦性心律\\'] = 82\\nto_123[\\'T波改变\\'] = -1\\nto_123[\\'窦性心动过缓\\'] = 81\\nto_123[\\'ST段改变\\'] = 78\\nto_123[\\'正常ECG\\'] = -1\\nto_123[\\'左心室高电压\\'] = -1\\nto_123[\\'ST-T改变\\'] = 61\\nto_123[\\'窦性心动过速\\'] = 83\\nto_123[\\'临界ECG\\'] = -1\\nto_123[\\'QRS低电压\\'] = 51\\nto_123[\\'房性早搏\\'] = -1\\nto_123[\\'电轴左偏\\'] = 46\\nto_123[\\'电轴右偏\\'] = 75\\nto_123[\\'心房颤动\\'] = 8\\nto_123[\\'异常ECG\\'] = -1\\nto_123[\\'室性早搏\\'] = 68\\nto_123[\\'完全性右束支传导阻滞\\'] = 24\\nto_123[\\'窦性心律不齐\\'] = 80\\nto_123[\\'左心室肥大\\'] = 49\\nto_123[\\'右束支传导阻滞\\'] = 76\\nto_123[\\'一度房室传导阻滞\\'] = -1\\nto_123[\\'快心室率\\'] = -1\\nto_123[\\'不完全性右束支传导阻滞\\'] = 33\\nto_123[\\'非特异性T波异常\\'] = -1\\nto_123[\\'QT间期延长\\'] = 69\\nto_123[\\'左前分支传导阻滞\\'] = 42\\nto_123[\\'非特异性ST段异常\\'] = -1\\nto_123[\\'差异性传导\\'] = -1\\nto_123[\\'非特异性ST段与T波异常\\'] = 61\\nto_123[\\'起搏心律\\'] = 63\\nto_123[\\'短PR间期\\'] = 79\\nto_123[\\'下壁异常Q波\\'] = 71\\nto_123[\\'快室率心房颤动\\'] = 8\\nto_123[\\'逆钟向转位\\'] = -1\\nto_123[\\'室内差异性传导\\'] = -1\\nto_123[\\'早期复极化\\'] = 27\\nto_123[\\'二联律\\'] = -1\\nto_123[\\'室上性早搏\\'] = 87\\nto_123[\\'顺钟向转位\\'] = -1\\nto_123[\\'复极化异常\\'] = -1\\nto_123[\\'未下传的房性早搏\\'] = -1\\nto_123[\\'肺心病型\\'] = -1\\nto_123[\\'慢心室率\\'] = -1\\nto_123[\\'短串房性心动过速\\'] = 13\\nto_123[\\'非特异性室内传导延迟\\'] = -1\\nto_123[\\'右心房扩大\\'] = 74\\nto_123[\\'左束支传导阻滞\\'] = 47\\nto_123[\\'前间壁R波递增不良\\'] = 72\\nto_123[\\'右心室肥大\\'] = 77\\nto_123[\\'房室传导延缓\\'] = 65\\nto_123[\\'双分支传导阻滞\\'] = 19\\nto_123[\\'非特异性室内传导阻滞\\'] = 60\\nto_123[\\'肺型P波\\'] = -1\\nto_123[\\'完全性左束支传导阻滞\\'] = -1\\nto_123[\\'融合波\\'] = -1\\n\\nf = open(\\'ori_round1_label_to_123_lalel\\',\\'w+\\')\\nfor key in disease_dict:\\n    assert key in to_123\\n    out_str = [str(key), str(disease_dict[key]), str(to_123[key])]\\n    f.write(\\'\\t\\'.join(out_str) + \\'\\n\\')\\nf.close()\\n\\nori_round1_label_to_123_lalel = []\\nfor line in open(\\'ori_round1_label_to_123_lalel\\'):\\n    ori_round1_label_to_123_lalel.append(line.strip())\\n\\'\\n\\'.join(ori_round1_label_to_123_lalel)\\n\\ndef get_train_data(path):\\n    train_data = []\\n    for dirname, dirs, filenames in os.walk(path):\\n        #filenames = sorted(filenames)\\n        filenames.sort(key=lambda f: int(\\'\\'.join(filter(str.isdigit, f))))\\n        for file_count, filename in tqdm(enumerate(filenames)):\\n            address = os.path.join(dirname, filename)\\n            #if file_count == 10000: break\\n            with open(address,\\'r\\') as f:\\n                individual = []\\n                for line, v in enumerate(f):\\n                    if line == 0: continue\\n                    v = v.split()\\n                    #print(v)\\n                    individual.append([float(value) for value in v])\\n                    del v\\n                individual = torch.FloatTensor(individual).transpose(0,1)\\n                #train_data[file_count] = individual\\n                train_data.append(individual)\\n                del individual\\n                f.close()\\n            #break\\n    train_data = torch.stack(train_data)\\n    return train_data\\n#get_train_data(\\'/kaggle/input/hf-round2-train/hf_round2_train\\')\\n#train_data = get_train_data(\\'/kaggle/input/hf-round2-train/hf_round2_train\\')\\ntrain_data = get_train_data(\\'/kaggle/input/ecgdata/hf_round1_train\\')\\n\\n#add up to 12 leads\\ndo_12leads = 1\\nif do_12leads:\\n    I = train_data[:,0]\\n    II = train_data[:,1]\\n    III=II-I\\n    aVR=-(I+II)/2\\n    aVL=I-II/2\\n    aVF=II-I/2\\n\\n    III = III.unsqueeze(1)\\n    aVR = aVR.unsqueeze(1)\\n    aVL = aVL.unsqueeze(1)\\n    aVF = aVF.unsqueeze(1)\\n    train_data = torch.cat([train_data, III, aVR, aVL, aVF],dim=1)\\n    del I, II, III, aVR, aVL, aVF\\ntrain_data.shape\\n\\nimport base64\\ndef write_data_to_file(output_path, datas, labels):\\n    key = 0\\n    with open(output_path,\\'w+\\') as f:\\n        for data,label in zip(datas,labels):\\n            output_str = [str(key), base64.b64encode(data.numpy().astype(np.float16)).decode(\"utf-8\"),\\n                              base64.b64encode(label.numpy().astype(np.float16)).decode(\"utf-8\"), \\'-1\\']\\n            f.write(\\'\\t\\'.join(output_str))\\n            #if key != 20035:\\n            if key != 24105:\\n                f.write(\\'\\n\\')\\n            key += 1\\n            #print(key)\\nwrite_data_to_file(\\'tianchi_round1\\', train_data, hot_labels)\\n\\n!tar -zcf tianchi_round1.gz tianchi_round1\\n!rm tianchi_round1\\n#exit(0)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"def load_labels(path):\n",
    "    #load labels\n",
    "    labels = []\n",
    "    with open(path,'r') as f:\n",
    "        for count, line in tqdm(enumerate(f)):\n",
    "            datas = line.split()\n",
    "            diseases = []\n",
    "            exist_age = 0\n",
    "            exist_sex = 0\n",
    "            if datas[1].isdigit():  exist_age = 1\n",
    "            if datas[1] == 'MALE' or datas[1] == 'FEMALE' : exist_sex = 1\n",
    "            if len(datas) > 2 and (datas[2] == 'MALE' or datas[2] == 'FEMALE') : exist_sex = 1\n",
    "            for disease in datas[1+exist_age+exist_sex:]:\n",
    "                diseases.append(disease_dict[disease])\n",
    "            labels.append(diseases)\n",
    "\n",
    "    #transfer labels to one-hot\n",
    "    hot_labels = []\n",
    "    for label in labels:\n",
    "        hot = [0]*len(disease_dict)\n",
    "        for disease in label:\n",
    "            hot[disease] = 1\n",
    "        hot_labels.append(hot)\n",
    "    hot_labels = torch.FloatTensor(hot_labels)\n",
    "    hot_labels.shape\n",
    "\n",
    "    num_dict = {}\n",
    "    for dis in labels:\n",
    "        for di in dis:\n",
    "            num_dict[di] = num_dict.get(di,0) + 1\n",
    "    #dict(sorted(num_dict.items()))\n",
    "    return labels, hot_labels, num_dict\n",
    "labels, hot_labels, num_dict = load_labels('/kaggle/input/ecgdata/hf_round1_label.txt')\n",
    "#labels, hot_labels, num_dict = load_labels('/kaggle/input/hf-round2-train/hf_round2_train.txt')\n",
    "\n",
    "#load diseases dict\n",
    "import pickle\n",
    "def load_disease_dict(path):\n",
    "    disease_dict = {}\n",
    "    with open(path,'r') as dict_f:\n",
    "        for count, line in enumerate(dict_f):\n",
    "            disease_dict[line.replace('\\n','')] = count\n",
    "    return disease_dict\n",
    "disease_dict = load_disease_dict('/kaggle/input/ecgdata/hf_round1_arrythmia.txt')\n",
    "pickle.dump(disease_dict,open('disease_dict_round1.pickle','wb+'))\n",
    "print(disease_dict)\n",
    "‘’‘\n",
    "print({k: v for k, v in sorted(num_dict.items(), key=lambda item: item[1], reverse=True)})\n",
    "for key in disease_dict:\n",
    "    index = disease_dict[key]\n",
    "    disease_dict[key] = num_dict[index]\n",
    "print({k: v for k, v in sorted(disease_dict.items(), key=lambda item: item[1], reverse=True)})\n",
    "’‘’\n",
    "\n",
    "to_123 = {}\n",
    "to_123['窦性心律'] = 82\n",
    "to_123['T波改变'] = -1\n",
    "to_123['窦性心动过缓'] = 81\n",
    "to_123['ST段改变'] = 78\n",
    "to_123['正常ECG'] = -1\n",
    "to_123['左心室高电压'] = -1\n",
    "to_123['ST-T改变'] = 61\n",
    "to_123['窦性心动过速'] = 83\n",
    "to_123['临界ECG'] = -1\n",
    "to_123['QRS低电压'] = 51\n",
    "to_123['房性早搏'] = -1\n",
    "to_123['电轴左偏'] = 46\n",
    "to_123['电轴右偏'] = 75\n",
    "to_123['心房颤动'] = 8\n",
    "to_123['异常ECG'] = -1\n",
    "to_123['室性早搏'] = 68\n",
    "to_123['完全性右束支传导阻滞'] = 24\n",
    "to_123['窦性心律不齐'] = 80\n",
    "to_123['左心室肥大'] = 49\n",
    "to_123['右束支传导阻滞'] = 76\n",
    "to_123['一度房室传导阻滞'] = -1\n",
    "to_123['快心室率'] = -1\n",
    "to_123['不完全性右束支传导阻滞'] = 33\n",
    "to_123['非特异性T波异常'] = -1\n",
    "to_123['QT间期延长'] = 69\n",
    "to_123['左前分支传导阻滞'] = 42\n",
    "to_123['非特异性ST段异常'] = -1\n",
    "to_123['差异性传导'] = -1\n",
    "to_123['非特异性ST段与T波异常'] = 61\n",
    "to_123['起搏心律'] = 63\n",
    "to_123['短PR间期'] = 79\n",
    "to_123['下壁异常Q波'] = 71\n",
    "to_123['快室率心房颤动'] = 8\n",
    "to_123['逆钟向转位'] = -1\n",
    "to_123['室内差异性传导'] = -1\n",
    "to_123['早期复极化'] = 27\n",
    "to_123['二联律'] = -1\n",
    "to_123['室上性早搏'] = 87\n",
    "to_123['顺钟向转位'] = -1\n",
    "to_123['复极化异常'] = -1\n",
    "to_123['未下传的房性早搏'] = -1\n",
    "to_123['肺心病型'] = -1\n",
    "to_123['慢心室率'] = -1\n",
    "to_123['短串房性心动过速'] = 13\n",
    "to_123['非特异性室内传导延迟'] = -1\n",
    "to_123['右心房扩大'] = 74\n",
    "to_123['左束支传导阻滞'] = 47\n",
    "to_123['前间壁R波递增不良'] = 72\n",
    "to_123['右心室肥大'] = 77\n",
    "to_123['房室传导延缓'] = 65\n",
    "to_123['双分支传导阻滞'] = 19\n",
    "to_123['非特异性室内传导阻滞'] = 60\n",
    "to_123['肺型P波'] = -1\n",
    "to_123['完全性左束支传导阻滞'] = -1\n",
    "to_123['融合波'] = -1\n",
    "\n",
    "f = open('ori_round1_label_to_123_lalel','w+')\n",
    "for key in disease_dict:\n",
    "    assert key in to_123\n",
    "    out_str = [str(key), str(disease_dict[key]), str(to_123[key])]\n",
    "    f.write('\\t'.join(out_str) + '\\n')\n",
    "f.close()\n",
    "\n",
    "ori_round1_label_to_123_lalel = []\n",
    "for line in open('ori_round1_label_to_123_lalel'):\n",
    "    ori_round1_label_to_123_lalel.append(line.strip())\n",
    "'\\n'.join(ori_round1_label_to_123_lalel)\n",
    "\n",
    "def get_train_data(path):\n",
    "    train_data = []\n",
    "    for dirname, dirs, filenames in os.walk(path):\n",
    "        #filenames = sorted(filenames)\n",
    "        filenames.sort(key=lambda f: int(''.join(filter(str.isdigit, f))))\n",
    "        for file_count, filename in tqdm(enumerate(filenames)):\n",
    "            address = os.path.join(dirname, filename)\n",
    "            #if file_count == 10000: break\n",
    "            with open(address,'r') as f:\n",
    "                individual = []\n",
    "                for line, v in enumerate(f):\n",
    "                    if line == 0: continue\n",
    "                    v = v.split()\n",
    "                    #print(v)\n",
    "                    individual.append([float(value) for value in v])\n",
    "                    del v\n",
    "                individual = torch.FloatTensor(individual).transpose(0,1)\n",
    "                #train_data[file_count] = individual\n",
    "                train_data.append(individual)\n",
    "                del individual\n",
    "                f.close()\n",
    "            #break\n",
    "    train_data = torch.stack(train_data)\n",
    "    return train_data\n",
    "#get_train_data('/kaggle/input/hf-round2-train/hf_round2_train')\n",
    "#train_data = get_train_data('/kaggle/input/hf-round2-train/hf_round2_train')\n",
    "train_data = get_train_data('/kaggle/input/ecgdata/hf_round1_train')\n",
    "\n",
    "#add up to 12 leads\n",
    "do_12leads = 1\n",
    "if do_12leads:\n",
    "    I = train_data[:,0]\n",
    "    II = train_data[:,1]\n",
    "    III=II-I\n",
    "    aVR=-(I+II)/2\n",
    "    aVL=I-II/2\n",
    "    aVF=II-I/2\n",
    "\n",
    "    III = III.unsqueeze(1)\n",
    "    aVR = aVR.unsqueeze(1)\n",
    "    aVL = aVL.unsqueeze(1)\n",
    "    aVF = aVF.unsqueeze(1)\n",
    "    train_data = torch.cat([train_data, III, aVR, aVL, aVF],dim=1)\n",
    "    del I, II, III, aVR, aVL, aVF\n",
    "train_data.shape\n",
    "\n",
    "import base64\n",
    "def write_data_to_file(output_path, datas, labels):\n",
    "    key = 0\n",
    "    with open(output_path,'w+') as f:\n",
    "        for data,label in zip(datas,labels):\n",
    "            output_str = [str(key), base64.b64encode(data.numpy().astype(np.float16)).decode(\"utf-8\"),\n",
    "                              base64.b64encode(label.numpy().astype(np.float16)).decode(\"utf-8\"), '-1']\n",
    "            f.write('\\t'.join(output_str))\n",
    "            #if key != 20035:\n",
    "            if key != 24105:\n",
    "                f.write('\\n')\n",
    "            key += 1\n",
    "            #print(key)\n",
    "write_data_to_file('tianchi_round1', train_data, hot_labels)\n",
    "\n",
    "!tar -zcf tianchi_round1.gz tianchi_round1\n",
    "!rm tianchi_round1\n",
    "#exit(0)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "072f25c7b8ba4c948b04cbb9cafe123f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4e337b04e21343a1bb56c799206c11ba",
        "IPY_MODEL_0bae8917c0494a43b28b3aac2c4f4f41"
       ],
       "layout": "IPY_MODEL_230829232f1540d08273e354de8a8dfa"
      }
     },
     "07a0007adcc8493fb3a1c9334f9a6325": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "0bae8917c0494a43b28b3aac2c4f4f41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_1578e32030044f0186c63f5b47741d9d",
       "placeholder": "​",
       "style": "IPY_MODEL_07a0007adcc8493fb3a1c9334f9a6325",
       "value": " 17207/24106 [05:44&lt;02:23, 47.97it/s]"
      }
     },
     "1578e32030044f0186c63f5b47741d9d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "230829232f1540d08273e354de8a8dfa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4e337b04e21343a1bb56c799206c11ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "",
       "description": " 71%",
       "description_tooltip": null,
       "layout": "IPY_MODEL_de38531b308d4a3aa56280abcae47c42",
       "max": 24106.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_f9d073ae5f6347c9a9492d89ed61a190",
       "value": 17212.0
      }
     },
     "de38531b308d4a3aa56280abcae47c42": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f9d073ae5f6347c9a9492d89ed61a190": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": "initial"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
